# ===== pipeline.py (ë©”ì¸ RAG íŒŒì´í”„ë¼ì¸) =====
import time
from typing import Any, Dict, List
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# ê¸°ì¡´ í•¨ìˆ˜ë“¤ì„ ëª¨ë“ˆì—ì„œ import
from .data_loaders import _load_web_docs, _load_lending_guide, _load_recommend_docs
from .text_processing import _split_docs, _get_or_create_vectorstore
from .retrievers import MetadataAwareCrossEncoderReranker, MetadataAwareRetriever
from .prompts import BOOK_PROMPT, LIBRARY_PROMPT
from .utils import classify_simple, QueryType, validate_book_answer
from .config import EMBED_MODEL

# ì „ì—­ ì´ˆê¸°í™” (ê¸°ì¡´ê³¼ ë™ì¼)
print("\nğŸš€ ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘...")
web_docs = _load_web_docs()
lending_docs = _load_lending_guide()  # ìƒˆë¡œ ì¶”ê°€
recommend_docs = _load_recommend_docs()
ALL_DOCS = web_docs + lending_docs + recommend_docs
SPLITS = _split_docs(ALL_DOCS)
print(f"ğŸ“„ ë¬¸ì„œ {len(ALL_DOCS)}ê°œ â†’ ì²­í¬ {len(SPLITS)}ê°œ")

VECTORSTORE = _get_or_create_vectorstore(SPLITS)

print("\nğŸš€ ë©”íƒ€ë°ì´í„° ì¸ì‹ CrossEncoder Rerankerë¡œ ì—…ê·¸ë ˆì´ë“œ ì¤‘...")

# ë©”íƒ€ë°ì´í„° ì¸ì‹ Reranker ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)
metadata_aware_reranker = MetadataAwareCrossEncoderReranker(
    model_name="cross-encoder/ms-marco-MiniLM-L-6-v2",
    top_k=3
)

# ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
Book_RETRIEVER = MetadataAwareRetriever(
    vectorstore=VECTORSTORE,
    reranker=metadata_aware_reranker,
    initial_k=15
)

Library_RETRIEVER = VECTORSTORE.as_retriever(
    search_type="mmr", search_kwargs={"k": 5}
)

print("âœ… Custom Reranker íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")

# LLM ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
import os
MODEL_NAME = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
LLM = ChatOpenAI(model=MODEL_NAME, temperature=0)

print("ğŸ¯ RAG íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ!\n")

# ë©”ì¸ ask í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ì™„ì „ ë™ì¼)
def ask(question: str, history: List[dict] | None = None) -> Dict[str, Any]:
    """ì™¸ë¶€ì—ì„œ í˜¸ì¶œë˜ëŠ” ì§„ì…ì : ì§ˆë¬¸ì„ ë°›ì•„ ì¿¼ë¦¬ íƒ€ì…ë³„ ì²˜ë¦¬ + ì†ŒìŠ¤ ë°˜í™˜"""
    t0 = time.time()

    # ì¿¼ë¦¬ ë¶„ë¥˜
    query_type = classify_simple(question)

    # íƒ€ì…ë³„ ë¦¬íŠ¸ë¦¬ë²„ & í”„ë¡¬í”„íŠ¸ ì„ íƒ
    if query_type == QueryType.BOOK_RECOMMENDATION:
        retriever = Book_RETRIEVER
        prompt = BOOK_PROMPT
    else:
        retriever = Library_RETRIEVER
        prompt = LIBRARY_PROMPT

    retrieved_docs = retriever.invoke(question)

    # Contextë¥¼ ìˆ˜ë™ìœ¼ë¡œ êµ¬ì„± (Custom Retriever ì‚¬ìš© ì‹œ í•„ìš”)
    context = "\n\n".join([doc.page_content for doc in retrieved_docs])
    
    chain = prompt | LLM | StrOutputParser()

    # (2) ë‹µë³€ ìƒì„± - ìˆ˜ë™ìœ¼ë¡œ contextì™€ question ì „ë‹¬
    answer = chain.invoke({
        "context": context,
        "question": question
    })

    # ë‹µë³€ í›„ì²˜ë¦¬ (í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬)
    if query_type == QueryType.BOOK_RECOMMENDATION:
        answer = validate_book_answer(answer, retrieved_docs)

    # (3) ì†ŒìŠ¤ ë¬¸ì„œ ì¼ë¶€ ì¶”ì¶œ
    sources = []
    for d in (retrieved_docs or [])[:5]:
        sources.append({
        "í•™ë…„": d.metadata.get("í•™ë…„"),
        "í•™ê¸°": d.metadata.get("í•™ê¸°"),
        "ë¶„ì•¼": d.metadata.get("ë¶„ì•¼"),
        "preview": d.page_content[:120] + "..."
    })

    elapsed = time.time() - t0
    return {"answer": answer, "sources": sources, "usage": {"latency_sec": round(elapsed, 2)}}

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ 
if __name__ == "__main__":
    question = "4í•™ë…„ 1í•™ê¸° ê¸°ìˆ ê³¼í•™ ë¶„ì•¼ì—ì„œ ì¶”ì²œí•  ë„ì„œëŠ”?"
    print(f"ğŸ“ ì§ˆë¬¸: {question}")
    
    try:
        result = ask(question)
        print(f"ğŸ¤– ë‹µë³€:\n{result['answer']}")
        print(f"â±ï¸ ì‘ë‹µì‹œê°„: {result['usage']['latency_sec']}ì´ˆ")
        print(f"ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(result['sources'])}")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
