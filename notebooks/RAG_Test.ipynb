{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 총 문서 수: 133\n",
      "📄 청크 수: 2004\n",
      "\n",
      "🚀 벡터스토어 준비 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w0/ll3gcfv51rj1zzw056sn6_d00000gn/T/ipykernel_46648/2776256404.py:144: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceBgeEmbeddings(model_name=model_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 캐시 확인 중... (rag_ad024fc9efc5)\n",
      "📁 캐시 발견! 로드 중...\n",
      "✅ 캐시 로드 완료! 소요시간: 0.67초\n",
      "\n",
      "📁 벡터스토어 캐시 정보:\n",
      "----------------------------------------\n",
      "🔑 키: rag_829742be6a2d\n",
      "📅 생성: 2025-08-07T15:46\n",
      "🤖 모델: jhgan/ko-sroberta-multitask\n",
      "📄 문서 수: 3259\n",
      "💾 크기: 18.8MB\n",
      "--------------------\n",
      "🔑 키: rag_ad024fc9efc5\n",
      "📅 생성: 2025-08-07T18:25\n",
      "🤖 모델: jhgan/ko-sroberta-multitask\n",
      "📄 문서 수: 2004\n",
      "💾 크기: 11.1MB\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/songseung-yun/Desktop/HSU_Library_Backend/RAG/venv/lib/python3.13/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 RAG 시스템 준비 완료!\n",
      "💡 다음 실행시에는 캐시된 벡터스토어가 즉시 로드됩니다.\n",
      "\n",
      "============================================================\n",
      "============================================================\n",
      "[HUMAN]\n",
      "책 추천해줘\n",
      "\n",
      "[AI]\n",
      "책 추천해드릴게요. '서민 독서 :책은 왜 읽어야 하는가'와 'Absolute Java'를 추천합니다.\n",
      "\n",
      "⏱️ 응답 시간: 2.42초\n"
     ]
    }
   ],
   "source": [
    "# === 1. 기본 설정 ===\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import bs4\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# 프로젝트 이름 및 환경변수 불러오기\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG_TUTORIAL\"\n",
    "load_dotenv()\n",
    "\n",
    "# === 캐시 매니저 클래스 ===\n",
    "class VectorStoreCache:\n",
    "    \"\"\"벡터스토어 캐시 관리\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir=\"vectorstore_cache\"):\n",
    "        self.cache_dir = Path.home() / cache_dir\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        self.metadata_file = self.cache_dir / \"cache_metadata.json\"\n",
    "        \n",
    "    def _generate_cache_key(self, documents, model_name):\n",
    "        \"\"\"캐시 키 생성\"\"\"\n",
    "        doc_sample = \"\"\n",
    "        for doc in documents[:5]:\n",
    "            doc_sample += doc.page_content[:50]\n",
    "        \n",
    "        config_str = f\"{model_name}_{len(documents)}\"\n",
    "        full_content = doc_sample + config_str\n",
    "        \n",
    "        cache_key = hashlib.sha256(full_content.encode()).hexdigest()[:12]\n",
    "        return f\"rag_{cache_key}\"\n",
    "    \n",
    "    def _load_metadata(self):\n",
    "        \"\"\"메타데이터 로드\"\"\"\n",
    "        if self.metadata_file.exists():\n",
    "            with open(self.metadata_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def _save_metadata(self, metadata):\n",
    "        \"\"\"메타데이터 저장\"\"\"\n",
    "        with open(self.metadata_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    def load_cached_vectorstore(self, documents, model_name, embedding_model):\n",
    "        \"\"\"캐시된 벡터스토어 로드 시도\"\"\"\n",
    "        \n",
    "        cache_key = self._generate_cache_key(documents, model_name)\n",
    "        cache_path = self.cache_dir / cache_key\n",
    "        \n",
    "        print(f\"🔍 캐시 확인 중... ({cache_key})\")\n",
    "        \n",
    "        if cache_path.exists():\n",
    "            try:\n",
    "                print(\"📁 캐시 발견! 로드 중...\")\n",
    "                start_time = time.time()\n",
    "                \n",
    "                vectorstore = FAISS.load_local(str(cache_path), embedding_model, allow_dangerous_deserialization=True)\n",
    "                \n",
    "                load_time = time.time() - start_time\n",
    "                print(f\"✅ 캐시 로드 완료! 소요시간: {load_time:.2f}초\")\n",
    "                \n",
    "                return vectorstore\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 캐시 로드 실패: {e}\")\n",
    "                print(\"새로 생성합니다...\")\n",
    "        else:\n",
    "            print(\"캐시가 없습니다. 새로 생성합니다...\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def save_vectorstore(self, vectorstore, documents, model_name):\n",
    "        \"\"\"벡터스토어 캐시 저장\"\"\"\n",
    "        \n",
    "        cache_key = self._generate_cache_key(documents, model_name)\n",
    "        cache_path = self.cache_dir / cache_key\n",
    "        \n",
    "        print(f\"💾 벡터스토어 캐시 저장 중... ({cache_key})\")\n",
    "        \n",
    "        try:\n",
    "            vectorstore.save_local(str(cache_path))\n",
    "            \n",
    "            # 메타데이터 저장\n",
    "            metadata = self._load_metadata()\n",
    "            metadata[cache_key] = {\n",
    "                'created_at': datetime.now().isoformat(),\n",
    "                'model_name': model_name,\n",
    "                'document_count': len(documents)\n",
    "            }\n",
    "            self._save_metadata(metadata)\n",
    "            \n",
    "            print(\"✅ 캐시 저장 완료!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 캐시 저장 실패: {e}\")\n",
    "    \n",
    "    def show_cache_info(self):\n",
    "        \"\"\"캐시 정보 출력\"\"\"\n",
    "        metadata = self._load_metadata()\n",
    "        \n",
    "        print(\"\\n📁 벡터스토어 캐시 정보:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        if not metadata:\n",
    "            print(\"캐시된 벡터스토어가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        for cache_key, info in metadata.items():\n",
    "            print(f\"🔑 키: {cache_key}\")\n",
    "            print(f\"📅 생성: {info['created_at'][:16]}\")\n",
    "            print(f\"🤖 모델: {info['model_name']}\")\n",
    "            print(f\"📄 문서 수: {info['document_count']}\")\n",
    "            \n",
    "            cache_path = self.cache_dir / cache_key\n",
    "            if cache_path.exists():\n",
    "                size_mb = sum(f.stat().st_size for f in cache_path.rglob('*')) / (1024*1024)\n",
    "                print(f\"💾 크기: {size_mb:.1f}MB\")\n",
    "            print(\"-\" * 20)\n",
    "\n",
    "# === 캐시를 활용한 벡터스토어 생성 함수 ===\n",
    "def get_or_create_vectorstore(documents, model_name=\"jhgan/ko-sroberta-multitask\"):\n",
    "    \"\"\"캐시된 벡터스토어를 로드하거나 새로 생성\"\"\"\n",
    "    \n",
    "    # 캐시 매니저 초기화\n",
    "    cache_manager = VectorStoreCache()\n",
    "    \n",
    "    # 임베딩 모델 생성\n",
    "    embedding = HuggingFaceBgeEmbeddings(model_name=model_name)\n",
    "    \n",
    "    # 캐시된 벡터스토어 로드 시도\n",
    "    vectorstore = cache_manager.load_cached_vectorstore(documents, model_name, embedding)\n",
    "    \n",
    "    if vectorstore is not None:\n",
    "        # 캐시에서 성공적으로 로드됨\n",
    "        return vectorstore, cache_manager\n",
    "    \n",
    "    # 캐시가 없으면 새로 생성\n",
    "    print(\"🔨 새 벡터스토어 생성 중...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    vectorstore = FAISS.from_documents(documents, embedding=embedding)\n",
    "    \n",
    "    creation_time = time.time() - start_time\n",
    "    print(f\"✅ 벡터스토어 생성 완료! 소요시간: {creation_time:.2f}초\")\n",
    "    \n",
    "    # 캐시에 저장\n",
    "    cache_manager.save_vectorstore(vectorstore, documents, model_name)\n",
    "    \n",
    "    return vectorstore, cache_manager\n",
    "\n",
    "# === 2. 웹 문서 로드 ===\n",
    "url = \"https://hsel.hansung.ac.kr/intro_data.mir\"\n",
    "web_loader = WebBaseLoader(\n",
    "    web_path=(url,),\n",
    "    bs_kwargs={\"parse_only\": bs4.SoupStrainer(\"div\", attrs={\"id\": \"intro_rule\"})}\n",
    ")\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "# === 3. CSV 로드 및 월별 청크 구성 ===\n",
    "# 데이터 전처리: 컴퓨터공학과 10년치 학생 데이터 학생컬럼과 소속 컬럼은 중복되는 컬럼이기에 제외시킴\n",
    "# 1. 엑셀 파일 읽기\n",
    "df = pd.read_excel(\"BookLoan_10years_data.xlsx\")  # 예: \"book_data.xlsx\"\n",
    "# 2. CSV로 저장\n",
    "df.to_csv(\"BookLoan_10years_data.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "df = pd.read_csv(\"BookLoan_10years_data.csv\", encoding=\"utf-8\")\n",
    "df[\"대출월\"] = pd.to_datetime(df[\"대출일자\"]).dt.to_period(\"M\").astype(str)\n",
    "\n",
    "csv_docs = []\n",
    "for month, group in df.groupby(\"대출월\"):\n",
    "    rows = group.apply(\n",
    "        lambda row: (\n",
    "            f\"[대출일자] {row['대출일자']} | \"\n",
    "            f\"[학번] {row['학번']} | \"\n",
    "            f\"[연장횟수] {row['연장횟수']} | \"\n",
    "            f\"[청구기호] {row['청구기호']} | \"\n",
    "            f\"[등록번호] {row['등록번호']} | \"\n",
    "            f\"[서명] {row['서명']} | \"\n",
    "            f\"[저자] {row['저자']} | \"\n",
    "            f\"[보존서가] {row['보존서가 소장처']} - {row['보존서가 칸']}\"\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    content = \"\\n\".join(rows)\n",
    "    csv_docs.append(Document(page_content=content, metadata={\"month\": month}))\n",
    "\n",
    "# === 4. 문서 통합 및 청크 분할 ===\n",
    "all_docs = web_docs + csv_docs\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1800,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")\n",
    "splits = text_splitter.split_documents(all_docs)\n",
    "\n",
    "print(f\"📄 총 문서 수: {len(all_docs)}\")\n",
    "print(f\"📄 청크 수: {len(splits)}\")\n",
    "\n",
    "# === 5. 캐시를 활용한 벡터스토어 생성 ===\n",
    "print(\"\\n🚀 벡터스토어 준비 중...\")\n",
    "vectorstore, cache_manager = get_or_create_vectorstore(splits)\n",
    "\n",
    "# 캐시 정보 출력\n",
    "cache_manager.show_cache_info()\n",
    "\n",
    "# === 6. 리트리버 설정===\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10})\n",
    "\n",
    "# === 7. LLM + 프롬프트 + 체인 구성 ===\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# === 8. 질문 실행 함수 ===\n",
    "def ask(question: str):\n",
    "    print(\"===\" * 20)\n",
    "    print(f\"[HUMAN]\\n{question}\\n\")\n",
    "    start_time = time.time()\n",
    "    response = rag_chain.invoke(question)\n",
    "    response_time = time.time() - start_time\n",
    "    print(f\"[AI]\\n{response}\")\n",
    "    print(f\"\\n⏱️ 응답 시간: {response_time:.2f}초\")\n",
    "\n",
    "# === 9. 테스트 ===\n",
    "print(\"\\n🎯 RAG 시스템 준비 완료!\")\n",
    "print(\"💡 다음 실행시에는 캐시된 벡터스토어가 즉시 로드됩니다.\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "ask(\"책 추천해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[HUMAN]\n",
      "나는 한성대학교 3학년 재학중인 컴퓨터공학과 학생이야. 현재 금융권 IT 개발직군 취업준비중이야. 책을 추천해줘\n",
      "\n",
      "[AI]\n",
      "'이것이 취업을 위한 코딩 테스트다 with 파이썬 :취업과 이직을 결정하는 알고리즘 인터뷰 완벽 가이드' 책을 추천해드립니다. 해당 책은 IT 개발 직군 취업 준비에 도움이 될 수 있습니다. 파이썬을 활용한 코딩 테스트와 알고리즘 인터뷰에 대한 내용이 포함되어 있습니다.\n",
      "\n",
      "⏱️ 응답 시간: 2.40초\n"
     ]
    }
   ],
   "source": [
    "# 사용자의 질문이 구체적일수록 더욱 명확한 답변제공 (성능 여부는 사용자의 책임에 있음)\n",
    "ask(\"나는 한성대학교 3학년 재학중인 컴퓨터공학과 학생이야. 현재 금융권 IT 개발직군 취업준비중이야. 책을 추천해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
