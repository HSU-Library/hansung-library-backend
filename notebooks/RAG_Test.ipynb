{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ ì´ ë¬¸ì„œ ìˆ˜: 133\n",
      "ğŸ“„ ì²­í¬ ìˆ˜: 2004\n",
      "\n",
      "ğŸš€ ë²¡í„°ìŠ¤í† ì–´ ì¤€ë¹„ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w0/ll3gcfv51rj1zzw056sn6_d00000gn/T/ipykernel_46648/2776256404.py:144: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceBgeEmbeddings(model_name=model_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ìºì‹œ í™•ì¸ ì¤‘... (rag_ad024fc9efc5)\n",
      "ğŸ“ ìºì‹œ ë°œê²¬! ë¡œë“œ ì¤‘...\n",
      "âœ… ìºì‹œ ë¡œë“œ ì™„ë£Œ! ì†Œìš”ì‹œê°„: 0.67ì´ˆ\n",
      "\n",
      "ğŸ“ ë²¡í„°ìŠ¤í† ì–´ ìºì‹œ ì •ë³´:\n",
      "----------------------------------------\n",
      "ğŸ”‘ í‚¤: rag_829742be6a2d\n",
      "ğŸ“… ìƒì„±: 2025-08-07T15:46\n",
      "ğŸ¤– ëª¨ë¸: jhgan/ko-sroberta-multitask\n",
      "ğŸ“„ ë¬¸ì„œ ìˆ˜: 3259\n",
      "ğŸ’¾ í¬ê¸°: 18.8MB\n",
      "--------------------\n",
      "ğŸ”‘ í‚¤: rag_ad024fc9efc5\n",
      "ğŸ“… ìƒì„±: 2025-08-07T18:25\n",
      "ğŸ¤– ëª¨ë¸: jhgan/ko-sroberta-multitask\n",
      "ğŸ“„ ë¬¸ì„œ ìˆ˜: 2004\n",
      "ğŸ’¾ í¬ê¸°: 11.1MB\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/songseung-yun/Desktop/HSU_Library_Backend/RAG/venv/lib/python3.13/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\n",
      "ğŸ’¡ ë‹¤ìŒ ì‹¤í–‰ì‹œì—ëŠ” ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ê°€ ì¦‰ì‹œ ë¡œë“œë©ë‹ˆë‹¤.\n",
      "\n",
      "============================================================\n",
      "============================================================\n",
      "[HUMAN]\n",
      "ì±… ì¶”ì²œí•´ì¤˜\n",
      "\n",
      "[AI]\n",
      "ì±… ì¶”ì²œí•´ë“œë¦´ê²Œìš”. 'ì„œë¯¼ ë…ì„œ :ì±…ì€ ì™œ ì½ì–´ì•¼ í•˜ëŠ”ê°€'ì™€ 'Absolute Java'ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "\n",
      "â±ï¸ ì‘ë‹µ ì‹œê°„: 2.42ì´ˆ\n"
     ]
    }
   ],
   "source": [
    "# === 1. ê¸°ë³¸ ì„¤ì • ===\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import bs4\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ ë° í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG_TUTORIAL\"\n",
    "load_dotenv()\n",
    "\n",
    "# === ìºì‹œ ë§¤ë‹ˆì € í´ë˜ìŠ¤ ===\n",
    "class VectorStoreCache:\n",
    "    \"\"\"ë²¡í„°ìŠ¤í† ì–´ ìºì‹œ ê´€ë¦¬\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir=\"vectorstore_cache\"):\n",
    "        self.cache_dir = Path.home() / cache_dir\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        self.metadata_file = self.cache_dir / \"cache_metadata.json\"\n",
    "        \n",
    "    def _generate_cache_key(self, documents, model_name):\n",
    "        \"\"\"ìºì‹œ í‚¤ ìƒì„±\"\"\"\n",
    "        doc_sample = \"\"\n",
    "        for doc in documents[:5]:\n",
    "            doc_sample += doc.page_content[:50]\n",
    "        \n",
    "        config_str = f\"{model_name}_{len(documents)}\"\n",
    "        full_content = doc_sample + config_str\n",
    "        \n",
    "        cache_key = hashlib.sha256(full_content.encode()).hexdigest()[:12]\n",
    "        return f\"rag_{cache_key}\"\n",
    "    \n",
    "    def _load_metadata(self):\n",
    "        \"\"\"ë©”íƒ€ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "        if self.metadata_file.exists():\n",
    "            with open(self.metadata_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def _save_metadata(self, metadata):\n",
    "        \"\"\"ë©”íƒ€ë°ì´í„° ì €ì¥\"\"\"\n",
    "        with open(self.metadata_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    def load_cached_vectorstore(self, documents, model_name, embedding_model):\n",
    "        \"\"\"ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹œë„\"\"\"\n",
    "        \n",
    "        cache_key = self._generate_cache_key(documents, model_name)\n",
    "        cache_path = self.cache_dir / cache_key\n",
    "        \n",
    "        print(f\"ğŸ” ìºì‹œ í™•ì¸ ì¤‘... ({cache_key})\")\n",
    "        \n",
    "        if cache_path.exists():\n",
    "            try:\n",
    "                print(\"ğŸ“ ìºì‹œ ë°œê²¬! ë¡œë“œ ì¤‘...\")\n",
    "                start_time = time.time()\n",
    "                \n",
    "                vectorstore = FAISS.load_local(str(cache_path), embedding_model, allow_dangerous_deserialization=True)\n",
    "                \n",
    "                load_time = time.time() - start_time\n",
    "                print(f\"âœ… ìºì‹œ ë¡œë“œ ì™„ë£Œ! ì†Œìš”ì‹œê°„: {load_time:.2f}ì´ˆ\")\n",
    "                \n",
    "                return vectorstore\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "                print(\"ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "        else:\n",
    "            print(\"ìºì‹œê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def save_vectorstore(self, vectorstore, documents, model_name):\n",
    "        \"\"\"ë²¡í„°ìŠ¤í† ì–´ ìºì‹œ ì €ì¥\"\"\"\n",
    "        \n",
    "        cache_key = self._generate_cache_key(documents, model_name)\n",
    "        cache_path = self.cache_dir / cache_key\n",
    "        \n",
    "        print(f\"ğŸ’¾ ë²¡í„°ìŠ¤í† ì–´ ìºì‹œ ì €ì¥ ì¤‘... ({cache_key})\")\n",
    "        \n",
    "        try:\n",
    "            vectorstore.save_local(str(cache_path))\n",
    "            \n",
    "            # ë©”íƒ€ë°ì´í„° ì €ì¥\n",
    "            metadata = self._load_metadata()\n",
    "            metadata[cache_key] = {\n",
    "                'created_at': datetime.now().isoformat(),\n",
    "                'model_name': model_name,\n",
    "                'document_count': len(documents)\n",
    "            }\n",
    "            self._save_metadata(metadata)\n",
    "            \n",
    "            print(\"âœ… ìºì‹œ ì €ì¥ ì™„ë£Œ!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    def show_cache_info(self):\n",
    "        \"\"\"ìºì‹œ ì •ë³´ ì¶œë ¥\"\"\"\n",
    "        metadata = self._load_metadata()\n",
    "        \n",
    "        print(\"\\nğŸ“ ë²¡í„°ìŠ¤í† ì–´ ìºì‹œ ì •ë³´:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        if not metadata:\n",
    "            print(\"ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        for cache_key, info in metadata.items():\n",
    "            print(f\"ğŸ”‘ í‚¤: {cache_key}\")\n",
    "            print(f\"ğŸ“… ìƒì„±: {info['created_at'][:16]}\")\n",
    "            print(f\"ğŸ¤– ëª¨ë¸: {info['model_name']}\")\n",
    "            print(f\"ğŸ“„ ë¬¸ì„œ ìˆ˜: {info['document_count']}\")\n",
    "            \n",
    "            cache_path = self.cache_dir / cache_key\n",
    "            if cache_path.exists():\n",
    "                size_mb = sum(f.stat().st_size for f in cache_path.rglob('*')) / (1024*1024)\n",
    "                print(f\"ğŸ’¾ í¬ê¸°: {size_mb:.1f}MB\")\n",
    "            print(\"-\" * 20)\n",
    "\n",
    "# === ìºì‹œë¥¼ í™œìš©í•œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í•¨ìˆ˜ ===\n",
    "def get_or_create_vectorstore(documents, model_name=\"jhgan/ko-sroberta-multitask\"):\n",
    "    \"\"\"ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±\"\"\"\n",
    "    \n",
    "    # ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™”\n",
    "    cache_manager = VectorStoreCache()\n",
    "    \n",
    "    # ì„ë² ë”© ëª¨ë¸ ìƒì„±\n",
    "    embedding = HuggingFaceBgeEmbeddings(model_name=model_name)\n",
    "    \n",
    "    # ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹œë„\n",
    "    vectorstore = cache_manager.load_cached_vectorstore(documents, model_name, embedding)\n",
    "    \n",
    "    if vectorstore is not None:\n",
    "        # ìºì‹œì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë¨\n",
    "        return vectorstore, cache_manager\n",
    "    \n",
    "    # ìºì‹œê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±\n",
    "    print(\"ğŸ”¨ ìƒˆ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    vectorstore = FAISS.from_documents(documents, embedding=embedding)\n",
    "    \n",
    "    creation_time = time.time() - start_time\n",
    "    print(f\"âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ! ì†Œìš”ì‹œê°„: {creation_time:.2f}ì´ˆ\")\n",
    "    \n",
    "    # ìºì‹œì— ì €ì¥\n",
    "    cache_manager.save_vectorstore(vectorstore, documents, model_name)\n",
    "    \n",
    "    return vectorstore, cache_manager\n",
    "\n",
    "# === 2. ì›¹ ë¬¸ì„œ ë¡œë“œ ===\n",
    "url = \"https://hsel.hansung.ac.kr/intro_data.mir\"\n",
    "web_loader = WebBaseLoader(\n",
    "    web_path=(url,),\n",
    "    bs_kwargs={\"parse_only\": bs4.SoupStrainer(\"div\", attrs={\"id\": \"intro_rule\"})}\n",
    ")\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "# === 3. CSV ë¡œë“œ ë° ì›”ë³„ ì²­í¬ êµ¬ì„± ===\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬: ì»´í“¨í„°ê³µí•™ê³¼ 10ë…„ì¹˜ í•™ìƒ ë°ì´í„° í•™ìƒì»¬ëŸ¼ê³¼ ì†Œì† ì»¬ëŸ¼ì€ ì¤‘ë³µë˜ëŠ” ì»¬ëŸ¼ì´ê¸°ì— ì œì™¸ì‹œí‚´\n",
    "# 1. ì—‘ì…€ íŒŒì¼ ì½ê¸°\n",
    "df = pd.read_excel(\"BookLoan_10years_data.xlsx\")  # ì˜ˆ: \"book_data.xlsx\"\n",
    "# 2. CSVë¡œ ì €ì¥\n",
    "df.to_csv(\"BookLoan_10years_data.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "df = pd.read_csv(\"BookLoan_10years_data.csv\", encoding=\"utf-8\")\n",
    "df[\"ëŒ€ì¶œì›”\"] = pd.to_datetime(df[\"ëŒ€ì¶œì¼ì\"]).dt.to_period(\"M\").astype(str)\n",
    "\n",
    "csv_docs = []\n",
    "for month, group in df.groupby(\"ëŒ€ì¶œì›”\"):\n",
    "    rows = group.apply(\n",
    "        lambda row: (\n",
    "            f\"[ëŒ€ì¶œì¼ì] {row['ëŒ€ì¶œì¼ì']} | \"\n",
    "            f\"[í•™ë²ˆ] {row['í•™ë²ˆ']} | \"\n",
    "            f\"[ì—°ì¥íšŸìˆ˜] {row['ì—°ì¥íšŸìˆ˜']} | \"\n",
    "            f\"[ì²­êµ¬ê¸°í˜¸] {row['ì²­êµ¬ê¸°í˜¸']} | \"\n",
    "            f\"[ë“±ë¡ë²ˆí˜¸] {row['ë“±ë¡ë²ˆí˜¸']} | \"\n",
    "            f\"[ì„œëª…] {row['ì„œëª…']} | \"\n",
    "            f\"[ì €ì] {row['ì €ì']} | \"\n",
    "            f\"[ë³´ì¡´ì„œê°€] {row['ë³´ì¡´ì„œê°€ ì†Œì¥ì²˜']} - {row['ë³´ì¡´ì„œê°€ ì¹¸']}\"\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    content = \"\\n\".join(rows)\n",
    "    csv_docs.append(Document(page_content=content, metadata={\"month\": month}))\n",
    "\n",
    "# === 4. ë¬¸ì„œ í†µí•© ë° ì²­í¬ ë¶„í•  ===\n",
    "all_docs = web_docs + csv_docs\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1800,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")\n",
    "splits = text_splitter.split_documents(all_docs)\n",
    "\n",
    "print(f\"ğŸ“„ ì´ ë¬¸ì„œ ìˆ˜: {len(all_docs)}\")\n",
    "print(f\"ğŸ“„ ì²­í¬ ìˆ˜: {len(splits)}\")\n",
    "\n",
    "# === 5. ìºì‹œë¥¼ í™œìš©í•œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ===\n",
    "print(\"\\nğŸš€ ë²¡í„°ìŠ¤í† ì–´ ì¤€ë¹„ ì¤‘...\")\n",
    "vectorstore, cache_manager = get_or_create_vectorstore(splits)\n",
    "\n",
    "# ìºì‹œ ì •ë³´ ì¶œë ¥\n",
    "cache_manager.show_cache_info()\n",
    "\n",
    "# === 6. í˜„ì¬ ì›” ê¸°ì¤€ í•„í„°ë§ ë¦¬íŠ¸ë¦¬ë²„ ===\n",
    "current_month = datetime.now().strftime(\"%m\")\n",
    "\n",
    "def filter_by_month(docs):\n",
    "    return [doc for doc in docs if doc.metadata.get(\"month\") == current_month]\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10})\n",
    "filtered_retriever = retriever | RunnableLambda(filter_by_month)\n",
    "\n",
    "# === 7. LLM + í”„ë¡¬í”„íŠ¸ + ì²´ì¸ êµ¬ì„± ===\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# === 8. ì§ˆë¬¸ ì‹¤í–‰ í•¨ìˆ˜ ===\n",
    "def ask(question: str):\n",
    "    print(\"===\" * 20)\n",
    "    print(f\"[HUMAN]\\n{question}\\n\")\n",
    "    start_time = time.time()\n",
    "    response = rag_chain.invoke(question)\n",
    "    response_time = time.time() - start_time\n",
    "    print(f\"[AI]\\n{response}\")\n",
    "    print(f\"\\nâ±ï¸ ì‘ë‹µ ì‹œê°„: {response_time:.2f}ì´ˆ\")\n",
    "\n",
    "# === 9. í…ŒìŠ¤íŠ¸ ===\n",
    "print(\"\\nğŸ¯ RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"ğŸ’¡ ë‹¤ìŒ ì‹¤í–‰ì‹œì—ëŠ” ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ê°€ ì¦‰ì‹œ ë¡œë“œë©ë‹ˆë‹¤.\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "ask(\"ì±… ì¶”ì²œí•´ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[HUMAN]\n",
      "ë‚˜ëŠ” í•œì„±ëŒ€í•™êµ 3í•™ë…„ ì¬í•™ì¤‘ì¸ ì»´í“¨í„°ê³µí•™ê³¼ í•™ìƒì´ì•¼. í˜„ì¬ ê¸ˆìœµê¶Œ IT ê°œë°œì§êµ° ì·¨ì—…ì¤€ë¹„ì¤‘ì´ì•¼. ì±…ì„ ì¶”ì²œí•´ì¤˜\n",
      "\n",
      "[AI]\n",
      "'ì´ê²ƒì´ ì·¨ì—…ì„ ìœ„í•œ ì½”ë”© í…ŒìŠ¤íŠ¸ë‹¤ with íŒŒì´ì¬ :ì·¨ì—…ê³¼ ì´ì§ì„ ê²°ì •í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ ì¸í„°ë·° ì™„ë²½ ê°€ì´ë“œ' ì±…ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤. í•´ë‹¹ ì±…ì€ IT ê°œë°œ ì§êµ° ì·¨ì—… ì¤€ë¹„ì— ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒŒì´ì¬ì„ í™œìš©í•œ ì½”ë”© í…ŒìŠ¤íŠ¸ì™€ ì•Œê³ ë¦¬ì¦˜ ì¸í„°ë·°ì— ëŒ€í•œ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "â±ï¸ ì‘ë‹µ ì‹œê°„: 2.40ì´ˆ\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ êµ¬ì²´ì ì¼ìˆ˜ë¡ ë”ìš± ëª…í™•í•œ ë‹µë³€ì œê³µ (ì„±ëŠ¥ ì—¬ë¶€ëŠ” ì‚¬ìš©ìì˜ ì±…ì„ì— ìˆìŒ)\n",
    "ask(\"ë‚˜ëŠ” í•œì„±ëŒ€í•™êµ 3í•™ë…„ ì¬í•™ì¤‘ì¸ ì»´í“¨í„°ê³µí•™ê³¼ í•™ìƒì´ì•¼. í˜„ì¬ ê¸ˆìœµê¶Œ IT ê°œë°œì§êµ° ì·¨ì—…ì¤€ë¹„ì¤‘ì´ì•¼. ì±…ì„ ì¶”ì²œí•´ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
