{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. 기본 설정 ===\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import bs4\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# 프로젝트 이름 및 환경변수 불러오기\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG_TUTORIAL\"\n",
    "load_dotenv()\n",
    "\n",
    "# 2. 웹 문서 로드\n",
    "url = \"https://hsel.hansung.ac.kr/intro_data.mir\"\n",
    "web_loader = WebBaseLoader(\n",
    "    web_path=(url,),\n",
    "    bs_kwargs={\"parse_only\": bs4.SoupStrainer(\"div\", attrs={\"id\": \"intro_rule\"})}\n",
    ")\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "# 3. csv로드 월별 청크 구성\n",
    "# 서명,저자,출판사,출판년도,청구기호,대출일자,신분,소속(학과),학번,학년,대출횟수,보존서가 소장처,보존서가 칸\n",
    "df = pd.read_csv(\"book_data_RAG_location.csv\", encoding=\"utf-8\")\n",
    "df[\"대출월\"] = pd.to_datetime(df[\"대출일자\"]).dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# 문서 리스트 초기화 + 월별 데이터 그루핑하여 500개 단위로 문서 쪼개기\n",
    "csv_docs = []\n",
    "chunk_size = 100\n",
    "\n",
    "# 월별로 그룹핑\n",
    "for month, group in df.groupby(\"대출월\"):\n",
    "    for i in range(0, len(group), chunk_size):\n",
    "        chunk = group.iloc[i:i+chunk_size]\n",
    "        text = \"\\n\".join(\n",
    "            chunk.apply(\n",
    "                lambda row: (\n",
    "                    f\"[서명] {row['서명']} | \"\n",
    "                    f\"[저자] {row['저자']} | \"\n",
    "                    f\"[출판사] {row['출판사']} | \"\n",
    "                    f\"[출판년도] {row['출판년도']} | \"\n",
    "                    f\"[청구기호] {row['청구기호']} | \"\n",
    "                    f\"[대출일자] {row['대출일자']} | \"\n",
    "                    f\"[신분] {row['신분']} | \"\n",
    "                    f\"[소속] {row['소속(학과)']} | \"\n",
    "                    f\"[학번] {row['학번']} | \"\n",
    "                    f\"[학년] {row['학년']} | \"\n",
    "                    f\"[대출횟수] {row['대출횟수']} | \"\n",
    "                    f\"[보존서가] {row['보존서가 소장처']} - {row['보존서가 칸']}\"\n",
    "                ),\n",
    "                axis=1\n",
    "            )\n",
    "        )\n",
    "        csv_docs.append(Document(page_content=text, metadata={\"month\": month}))\n",
    "\n",
    "# 3. 문서 통합 및 청크 분할(월 + N개 단위로 쪼개기: 200줄씩 조갬)\n",
    "all_docs = web_docs + csv_docs\n",
    "\n",
    "print(f\"📄 전체 문서 수: {len(all_docs)}\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 600,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    ")\n",
    "splits = text_splitter.split_documents(all_docs)\n",
    "\n",
    "print(f\"문서 수: {len(all_docs)}\")\n",
    "print(f\"청크 수: {len(splits)}\")\n",
    "\n",
    "\n",
    "# 4. 벡터스토어 생성 (전체 문서)\n",
    "# 한국어 특화 임베딩 모델 bge-m3-korean\n",
    "# 한국어 특화 임베딩 모델\n",
    "embedding = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",  # 다국어 지원 모델\n",
    "    model_kwargs={'device': 'cpu'},  # GPU 없으면 cpu\n",
    "    encode_kwargs={'normalize_embeddings': True}  # 정규화\n",
    ")\n",
    "\n",
    "# 또는 한국어 특화 모델\n",
    "# embedding = HuggingFaceBgeEmbeddings(\n",
    "#     model_name=\"jhgan/ko-sroberta-multitask\",\n",
    "#     model_kwargs={'device': 'cpu'},\n",
    "#     encode_kwargs={'normalize_embeddings': True}\n",
    "\n",
    "# 벡터스토어 생성 (토큰 제한 없음)\n",
    "vectorstore = FAISS.from_documents(splits, embedding=embedding)\n",
    "print(\"✅ HuggingFace 임베딩으로 벡터스토어 생성 완료\")\n",
    "\n",
    "\n",
    "# 임베딩 속도 확인\n",
    "import time\n",
    "start = time.time()\n",
    "_ = embedding.embed_documents([\"테스트 문장입니다.\"] * 10)\n",
    "print(\"10개 임베딩 소요 시간:\", time.time() - start, \"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍎 맥북 M2 환경 확인...\n",
      "PyTorch 버전: 2.7.1\n",
      "MPS 지원: True\n",
      "MPS 사용 가능: True\n",
      "💻 CPU 코어 수: 8 (성능 코어 + 효율 코어)\n",
      "🚀 MPS(Apple GPU) 모드 사용\n",
      "🍎 Apple Silicon GPU(MPS) 사용\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w0/ll3gcfv51rj1zzw056sn6_d00000gn/T/ipykernel_43484/3340008866.py:179: LangChainDeprecationWarning: `encode_kwargs['show_progress_bar']` was deprecated in LangChain 0.2.5 and will be removed in 1.0. Use the show_progress method on HuggingFaceBgeEmbeddings instead.\n",
      "  embedding = HuggingFaceBgeEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 배치 크기: 32\n",
      "🍎 맥북 M2 최적화 벡터스토어 생성 시작!\n",
      "📁 캐시 디렉토리: /Users/songseung-yun/m2_vectorstore_cache\n",
      "\n",
      "🍎 맥북 M2 캐시 정보:\n",
      "--------------------------------------------------\n",
      "캐시된 벡터스토어가 없습니다.\n",
      "🔍 캐시 확인: m2_2982ed6c378f\n",
      "🔨 맥북 M2 최적화 벡터스토어 생성 중...\n",
      "⚙️ 배치 크기: 32 (디바이스: mps)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:05<00:00,  5.92s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:06<00:00,  6.60s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "M2 벡터스토어 생성: 100%|██████████| 357/357 [07:53<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 벡터스토어 생성 완료! 소요시간: 476.82초\n",
      "💾 캐시 저장: m2_2982ed6c378f\n",
      "✅ 캐시 저장 완료!\n",
      "\n",
      "🍎 맥북 M2 성능 테스트:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ 임베딩 속도: 15.3 문서/초\n",
      "📏 임베딩 차원: 768차원\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:05<00:00,  5.32s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 평균 검색 속도: 1.506초\n",
      "💾 메모리 사용량: 491.1MB\n",
      "\n",
      "🍎 맥북 M2 캐시 정보:\n",
      "--------------------------------------------------\n",
      "🔑 캐시: m2_2982ed6c378f\n",
      "📅 생성: 2025-08-07T15:24\n",
      "🤖 모델: jhgan/ko-sroberta-multitask\n",
      "📄 문서: 11447개\n",
      "💾 크기: 43.7MB\n",
      "------------------------------\n",
      "📊 총 캐시 크기: 43.7MB\n",
      "\n",
      "🎉 맥북 M2 최적화 완료!\n",
      "💡 팁: 다음 실행시에는 캐시된 벡터스토어를 즉시 로드합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === 맥북 M2 최적화 + 캐시 처리 코드 ===\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "\n",
    "# === 1. 맥북 M2 환경 확인 및 설정 ===\n",
    "\n",
    "def check_m2_environment():\n",
    "    \"\"\"맥북 M2 환경 확인 및 최적화 설정\"\"\"\n",
    "    \n",
    "    print(\"🍎 맥북 M2 환경 확인...\")\n",
    "    print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "    \n",
    "    # MPS (Metal Performance Shaders) 확인\n",
    "    mps_available = torch.backends.mps.is_available()\n",
    "    mps_built = torch.backends.mps.is_built()\n",
    "    \n",
    "    print(f\"MPS 지원: {mps_built}\")\n",
    "    print(f\"MPS 사용 가능: {mps_available}\")\n",
    "    \n",
    "    # CPU 정보\n",
    "    cpu_cores = multiprocessing.cpu_count()\n",
    "    print(f\"💻 CPU 코어 수: {cpu_cores} (성능 코어 + 효율 코어)\")\n",
    "    \n",
    "    # 디바이스 설정\n",
    "    if mps_available and mps_built:\n",
    "        device = 'mps'  # Apple Silicon GPU 사용\n",
    "        torch_dtype = torch.float32  # MPS는 float16이 불안정할 수 있음\n",
    "        print(\"🚀 MPS(Apple GPU) 모드 사용\")\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        torch_dtype = torch.float32\n",
    "        print(\"💻 CPU 모드 사용\")\n",
    "        \n",
    "        # CPU 성능 최적화 설정\n",
    "        torch.set_num_threads(cpu_cores)\n",
    "        os.environ[\"OMP_NUM_THREADS\"] = str(cpu_cores)\n",
    "        print(f\"🔧 CPU 스레드 최적화: {cpu_cores}개 스레드 사용\")\n",
    "    \n",
    "    return device, torch_dtype, cpu_cores\n",
    "\n",
    "# M2 환경 확인\n",
    "device, torch_dtype, cpu_cores = check_m2_environment()\n",
    "\n",
    "# === 2. 맥북 M2 전용 캐시 관리 ===\n",
    "\n",
    "class M2VectorStoreCache:\n",
    "    \"\"\"맥북 M2 최적화 캐시 관리\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir=\"m2_vectorstore_cache\"):\n",
    "        self.cache_dir = Path.home() / cache_dir  # 홈 디렉토리에 저장\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        self.metadata_file = self.cache_dir / \"m2_cache_metadata.json\"\n",
    "        print(f\"📁 캐시 디렉토리: {self.cache_dir}\")\n",
    "        \n",
    "    def _generate_cache_key(self, documents, model_name, chunk_size):\n",
    "        \"\"\"캐시 키 생성\"\"\"\n",
    "        doc_sample = \"\"\n",
    "        for doc in documents[:5]:  # 처음 5개 문서로 해시\n",
    "            doc_sample += doc.page_content[:50]\n",
    "        \n",
    "        config_str = f\"M2_{model_name}_{chunk_size}_{len(documents)}\"\n",
    "        full_content = doc_sample + config_str\n",
    "        \n",
    "        cache_key = hashlib.sha256(full_content.encode()).hexdigest()[:12]\n",
    "        return f\"m2_{cache_key}\"\n",
    "    \n",
    "    def _load_metadata(self):\n",
    "        \"\"\"메타데이터 로드\"\"\"\n",
    "        if self.metadata_file.exists():\n",
    "            with open(self.metadata_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def _save_metadata(self, metadata):\n",
    "        \"\"\"메타데이터 저장\"\"\"\n",
    "        with open(self.metadata_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    def show_cache_info(self):\n",
    "        \"\"\"캐시 정보 표시\"\"\"\n",
    "        metadata = self._load_metadata()\n",
    "        \n",
    "        print(\"\\n🍎 맥북 M2 캐시 정보:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        if not metadata:\n",
    "            print(\"캐시된 벡터스토어가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        total_size = 0\n",
    "        for cache_key, info in metadata.items():\n",
    "            print(f\"🔑 캐시: {cache_key}\")\n",
    "            print(f\"📅 생성: {info['created_at'][:16]}\")\n",
    "            print(f\"🤖 모델: {info['model_name']}\")\n",
    "            print(f\"📄 문서: {info['document_count']}개\")\n",
    "            \n",
    "            cache_path = self.cache_dir / cache_key\n",
    "            if cache_path.exists():\n",
    "                size_mb = sum(f.stat().st_size for f in cache_path.rglob('*')) / (1024*1024)\n",
    "                total_size += size_mb\n",
    "                print(f\"💾 크기: {size_mb:.1f}MB\")\n",
    "            print(\"-\" * 30)\n",
    "        \n",
    "        print(f\"📊 총 캐시 크기: {total_size:.1f}MB\")\n",
    "    \n",
    "    def load_if_cached(self, documents, model_name, chunk_size, embedding_model):\n",
    "        \"\"\"캐시 확인 및 로드\"\"\"\n",
    "        cache_key = self._generate_cache_key(documents, model_name, chunk_size)\n",
    "        cache_path = self.cache_dir / cache_key\n",
    "        \n",
    "        print(f\"🔍 캐시 확인: {cache_key}\")\n",
    "        \n",
    "        if cache_path.exists():\n",
    "            try:\n",
    "                print(\"⚡ 캐시 발견! 로드 중...\")\n",
    "                start_time = time.time()\n",
    "                \n",
    "                vectorstore = FAISS.load_local(str(cache_path), embedding_model)\n",
    "                \n",
    "                load_time = time.time() - start_time\n",
    "                print(f\"✅ 캐시 로드 성공! ({load_time:.2f}초)\")\n",
    "                return vectorstore\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 캐시 로드 실패: {e}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def save_to_cache(self, vectorstore, documents, model_name, chunk_size):\n",
    "        \"\"\"캐시에 저장\"\"\"\n",
    "        cache_key = self._generate_cache_key(documents, model_name, chunk_size)\n",
    "        cache_path = self.cache_dir / cache_key\n",
    "        \n",
    "        print(f\"💾 캐시 저장: {cache_key}\")\n",
    "        \n",
    "        try:\n",
    "            vectorstore.save_local(str(cache_path))\n",
    "            \n",
    "            # 메타데이터 업데이트\n",
    "            metadata = self._load_metadata()\n",
    "            metadata[cache_key] = {\n",
    "                'created_at': datetime.now().isoformat(),\n",
    "                'model_name': model_name,\n",
    "                'document_count': len(documents),\n",
    "                'chunk_size': chunk_size,\n",
    "                'device': device\n",
    "            }\n",
    "            self._save_metadata(metadata)\n",
    "            \n",
    "            print(\"✅ 캐시 저장 완료!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 캐시 저장 실패: {e}\")\n",
    "\n",
    "# === 3. 맥북 M2 최적화 임베딩 모델 ===\n",
    "\n",
    "def create_m2_optimized_embedding(device, torch_dtype, cpu_cores):\n",
    "    \"\"\"맥북 M2 최적화 임베딩 모델\"\"\"\n",
    "    \n",
    "    # M2에 최적화된 설정\n",
    "    if device == 'mps':\n",
    "        # MPS 사용시 - Apple Silicon GPU 활용\n",
    "        batch_size = 32\n",
    "        model_name = \"jhgan/ko-sroberta-multitask\"  # 한국어 특화\n",
    "        print(\"🍎 Apple Silicon GPU(MPS) 사용\")\n",
    "    else:\n",
    "        # CPU 사용시 - 멀티코어 최적화\n",
    "        batch_size = min(16, cpu_cores)  # 코어 수에 맞춰 배치 크기 조정\n",
    "        model_name = \"jhgan/ko-sbert-nli\"  # 더 가벼운 모델\n",
    "        print(f\"💻 CPU 멀티코어({cpu_cores}) 사용\")\n",
    "    \n",
    "    embedding = HuggingFaceBgeEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs={\n",
    "            'device': device,\n",
    "            'torch_dtype': torch_dtype\n",
    "        },\n",
    "        encode_kwargs={\n",
    "            'normalize_embeddings': True,\n",
    "            'batch_size': batch_size,\n",
    "            'show_progress_bar': True\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"📦 배치 크기: {batch_size}\")\n",
    "    return embedding, model_name\n",
    "\n",
    "# M2 최적화 임베딩 모델 생성\n",
    "embedding, model_name = create_m2_optimized_embedding(device, torch_dtype, cpu_cores)\n",
    "\n",
    "# === 4. M2 최적화 벡터스토어 생성 함수 ===\n",
    "\n",
    "def create_m2_vectorstore(documents, chunk_size=600):\n",
    "    \"\"\"맥북 M2 최적화 벡터스토어 생성\"\"\"\n",
    "    \n",
    "    # 캐시 매니저\n",
    "    cache = M2VectorStoreCache()\n",
    "    cache.show_cache_info()\n",
    "    \n",
    "    # 캐시에서 로드 시도\n",
    "    vectorstore = cache.load_if_cached(documents, model_name, chunk_size, embedding)\n",
    "    if vectorstore:\n",
    "        return vectorstore, cache\n",
    "    \n",
    "    # 새로 생성\n",
    "    print(\"🔨 맥북 M2 최적화 벡터스토어 생성 중...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # M2에 최적화된 배치 크기\n",
    "    if device == 'mps':\n",
    "        batch_size = 32  # MPS는 중간 크기\n",
    "    else:\n",
    "        batch_size = min(24, cpu_cores * 2)  # CPU는 코어 수 * 2\n",
    "    \n",
    "    print(f\"⚙️ 배치 크기: {batch_size} (디바이스: {device})\")\n",
    "    \n",
    "    # 배치 처리로 생성\n",
    "    if len(documents) <= batch_size:\n",
    "        vectorstore = FAISS.from_documents(documents, embedding)\n",
    "    else:\n",
    "        from tqdm import tqdm\n",
    "        \n",
    "        # 첫 번째 배치\n",
    "        vectorstore = FAISS.from_documents(documents[:batch_size], embedding)\n",
    "        \n",
    "        # 나머지 배치\n",
    "        for i in tqdm(range(batch_size, len(documents), batch_size), \n",
    "                      desc=\"M2 벡터스토어 생성\", \n",
    "                      bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'):\n",
    "            batch = documents[i:i+batch_size]\n",
    "            batch_store = FAISS.from_documents(batch, embedding)\n",
    "            vectorstore.merge_from(batch_store)\n",
    "            \n",
    "            # M2 칩 과열 방지를 위한 작은 딜레이 (선택사항)\n",
    "            if device == 'mps':\n",
    "                time.sleep(0.1)\n",
    "    \n",
    "    creation_time = time.time() - start_time\n",
    "    print(f\"✅ 벡터스토어 생성 완료! 소요시간: {creation_time:.2f}초\")\n",
    "    \n",
    "    # 캐시에 저장\n",
    "    cache.save_to_cache(vectorstore, documents, model_name, chunk_size)\n",
    "    \n",
    "    return vectorstore, cache\n",
    "\n",
    "# === 5. M2 성능 테스트 함수 ===\n",
    "\n",
    "def test_m2_performance(vectorstore, embedding):\n",
    "    \"\"\"맥북 M2 성능 테스트\"\"\"\n",
    "    \n",
    "    print(\"\\n🍎 맥북 M2 성능 테스트:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # 임베딩 속도 테스트\n",
    "    test_texts = [\n",
    "        \"한성대학교 도서관 이용 규정\",\n",
    "        \"컴퓨터공학과 학생 도서 대출\",\n",
    "        \"데이터베이스 설계 관련 서적\",\n",
    "        \"인문학 도서 대출 현황 분석\"\n",
    "    ] * 10  # 40개 텍스트\n",
    "    \n",
    "    start = time.time()\n",
    "    embeddings_result = embedding.embed_documents(test_texts)\n",
    "    embed_time = time.time() - start\n",
    "    \n",
    "    print(f\"⚡ 임베딩 속도: {len(test_texts)/embed_time:.1f} 문서/초\")\n",
    "    print(f\"📏 임베딩 차원: {len(embeddings_result[0])}차원\")\n",
    "    \n",
    "    # 검색 속도 테스트\n",
    "    queries = [\"컴퓨터공학과\", \"도서 대출\", \"한성대학교\", \"데이터베이스\"]\n",
    "    \n",
    "    total_search_time = 0\n",
    "    for query in queries:\n",
    "        start = time.time()\n",
    "        results = vectorstore.similarity_search(query, k=3)\n",
    "        search_time = time.time() - start\n",
    "        total_search_time += search_time\n",
    "    \n",
    "    avg_search_time = total_search_time / len(queries)\n",
    "    print(f\"🔍 평균 검색 속도: {avg_search_time:.3f}초\")\n",
    "    \n",
    "    # 메모리 사용량 (선택사항)\n",
    "    try:\n",
    "        import psutil\n",
    "        process = psutil.Process()\n",
    "        memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "        print(f\"💾 메모리 사용량: {memory_mb:.1f}MB\")\n",
    "    except ImportError:\n",
    "        print(\"💾 메모리 정보: psutil 설치 필요\")\n",
    "\n",
    "# === 6. 실제 실행 ===\n",
    "\n",
    "print(\"🍎 맥북 M2 최적화 벡터스토어 생성 시작!\")\n",
    "\n",
    "# 벡터스토어 생성 (캐시 자동 처리)\n",
    "vectorstore, cache_manager = create_m2_vectorstore(splits, chunk_size=600)\n",
    "\n",
    "# 성능 테스트\n",
    "test_m2_performance(vectorstore, embedding)\n",
    "\n",
    "# 최종 캐시 정보\n",
    "cache_manager.show_cache_info()\n",
    "\n",
    "print(\"\\n🎉 맥북 M2 최적화 완료!\")\n",
    "print(\"💡 팁: 다음 실행시에는 캐시된 벡터스토어를 즉시 로드합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. 기본 설정 ===\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import bs4\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# 프로젝트 이름 및 환경변수 불러오기\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG_TUTORIAL\"\n",
    "load_dotenv()\n",
    "\n",
    "# 2. 웹 문서 로드\n",
    "url = \"https://hsel.hansung.ac.kr/intro_data.mir\"\n",
    "web_loader = WebBaseLoader(\n",
    "    web_path=(url,),\n",
    "    bs_kwargs={\"parse_only\": bs4.SoupStrainer(\"div\", attrs={\"id\": \"intro_rule\"})}\n",
    ")\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "# 3. csv로드 월별 청크 구성\n",
    "# 서명,저자,출판사,출판년도,청구기호,대출일자,신분,소속(학과),학번,학년,대출횟수,보존서가 소장처,보존서가 칸\n",
    "df = pd.read_csv(\"book_data_RAG_location.csv\", encoding=\"utf-8\")\n",
    "df[\"대출월\"] = pd.to_datetime(df[\"대출일자\"]).dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# 문서 리스트 초기화 + 월별 데이터 그루핑하여 500개 단위로 문서 쪼개기\n",
    "csv_docs = []\n",
    "chunk_size = 100\n",
    "\n",
    "# 월별로 그룹핑\n",
    "for month, group in df.groupby(\"대출월\"):\n",
    "    for i in range(0, len(group), chunk_size):\n",
    "        chunk = group.iloc[i:i+chunk_size]\n",
    "        text = \"\\n\".join(\n",
    "            chunk.apply(\n",
    "                lambda row: (\n",
    "                    f\"[서명] {row['서명']} | \"\n",
    "                    f\"[저자] {row['저자']} | \"\n",
    "                    f\"[출판사] {row['출판사']} | \"\n",
    "                    f\"[출판년도] {row['출판년도']} | \"\n",
    "                    f\"[청구기호] {row['청구기호']} | \"\n",
    "                    f\"[대출일자] {row['대출일자']} | \"\n",
    "                    f\"[신분] {row['신분']} | \"\n",
    "                    f\"[소속] {row['소속(학과)']} | \"\n",
    "                    f\"[학번] {row['학번']} | \"\n",
    "                    f\"[학년] {row['학년']} | \"\n",
    "                    f\"[대출횟수] {row['대출횟수']} | \"\n",
    "                    f\"[보존서가] {row['보존서가 소장처']} - {row['보존서가 칸']}\"\n",
    "                ),\n",
    "                axis=1\n",
    "            )\n",
    "        )\n",
    "        csv_docs.append(Document(page_content=text, metadata={\"month\": month}))\n",
    "\n",
    "# 3. 문서 통합 및 청크 분할(월 + N개 단위로 쪼개기: 200줄씩 조갬)\n",
    "all_docs = web_docs + csv_docs\n",
    "\n",
    "print(f\"📄 전체 문서 수: {len(all_docs)}\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 600,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    ")\n",
    "splits = text_splitter.split_documents(all_docs)\n",
    "\n",
    "print(f\"문서 수: {len(all_docs)}\")\n",
    "print(f\"청크 수: {len(splits)}\")\n",
    "\n",
    "# 또는 한국어 특화 모델\n",
    "# embedding = HuggingFaceBgeEmbeddings(\n",
    "#     model_name=\"jhgan/ko-sroberta-multitask\",\n",
    "#     model_kwargs={'device': 'cpu'},\n",
    "#     encode_kwargs={'normalize_embeddings': True}\n",
    "\n",
    "# 벡터스토어 생성 (토큰 제한 없음)\n",
    "vectorstore = FAISS.from_documents(splits, embedding=embedding)\n",
    "print(\"✅ HuggingFace 임베딩으로 벡터스토어 생성 완료\")\n",
    "\n",
    "\n",
    "# 임베딩 속도 확인\n",
    "import time\n",
    "start = time.time()\n",
    "_ = embedding.embed_documents([\"테스트 문장입니다.\"] * 10)\n",
    "print(\"10개 임베딩 소요 시간:\", time.time() - start, \"초\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
