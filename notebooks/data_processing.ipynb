{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì›ë³¸ë°ì´í„° ì „ì²˜ë¦¬\n",
    "1. ë„ì„œ ì¢…ë¥˜ì— ë”°ë¼ ë°ì´í„°ì…‹ì„ grouping, ë¶„ì•¼ â†’ í•™ë…„ â†’ í•™ê¸° ìˆœì„œë¡œ ì •ë ¬\n",
    "2. í•™ë…„ ë° í•™ê¸°ì— ë§ëŠ” í•™ìƒ ë¶„ë¥˜ (ì˜ˆ: 1í•™ë…„ 1í•™ê¸°, 4í•™ë…„ 2í•™ê¸°)\n",
    "3. ë„ì„œë³„ ëŒ€ì¶œ íšŸìˆ˜ ì§‘ê³„\n",
    "4. ê°™ì€ ì‚¬ìš©ìê°€ ëŒ€ì¶œí•  ëŒ€ì¶œ íšŸìˆ˜ ê°€ëŠ¥ì„±ì„ ë°©ì§€í•˜ì—¬ ë„ì„œ ëŒ€ì¶œ í•™ìƒ ìˆ˜ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"../backend/data/BookLoan_10years_data.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# ë‚ ì§œ ë³€í™˜\n",
    "df[\"ëŒ€ì¶œì¼ì\"] = pd.to_datetime(df[\"ëŒ€ì¶œì¼ì\"])\n",
    "\n",
    "# ì…í•™ë…„ë„ ì¶”ë¡  (í•™ë²ˆ ì• 2ìë¦¬)\n",
    "df[\"ì…í•™ë…„ë„\"] = 2000 + df[\"í•™ë²ˆ\"].astype(str).str[:2].astype(int)\n",
    "\n",
    "# í˜„ì¬ í•™ë…„ (ìµœëŒ€ 4í•™ë…„)\n",
    "df[\"ì¬í•™ë…„ì°¨\"] = datetime.now().year - df[\"ì…í•™ë…„ë„\"]\n",
    "df[\"í•™ë…„\"] = df[\"ì¬í•™ë…„ì°¨\"].apply(lambda x: x if x <= 4 else 4)\n",
    "\n",
    "# í•™ê¸° ê³„ì‚° (3~9ì›” = 1í•™ê¸°, 10~2ì›” = 2í•™ê¸°)\n",
    "df[\"ì›”\"] = df[\"ëŒ€ì¶œì¼ì\"].dt.month\n",
    "df[\"í•™ê¸°\"] = df[\"ì›”\"].apply(lambda m: 1 if 3 <= m <= 9 else 2)\n",
    "\n",
    "# ì²­êµ¬ê¸°í˜¸ ë¶„ë¥˜ ë§¤í•‘\n",
    "def classify_subject(code):\n",
    "    try:\n",
    "         # ë¬¸ìì—´ì—ì„œ ì—°ì†ëœ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: \"657.3 ã„¹468ã…ˆ v\" â†’ \"657\")\n",
    "        match = re.match(r\"(\\d{3})\", str(code).strip())\n",
    "        if not match:\n",
    "            return \"ê¸°íƒ€\"\n",
    "        num = int(match.group(1))  # 3ìë¦¬ ì •ìˆ˜\n",
    "    except:\n",
    "        return \"ê¸°íƒ€\"\n",
    "\n",
    "    if 0 <= num <= 99: return \"ì´ë¥˜\"\n",
    "    elif 100 <= num <= 199: return \"ì² í•™\"\n",
    "    elif 200 <= num <= 299: return \"ì¢…êµ\"\n",
    "    elif 300 <= num <= 399: return \"ì‚¬íšŒê³¼í•™\"\n",
    "    elif 400 <= num <= 499: return \"ìì—°ê³¼í•™\"\n",
    "    elif 500 <= num <= 599: return \"ê¸°ìˆ ê³¼í•™\"\n",
    "    elif 600 <= num <= 699: return \"ì˜ˆìˆ \"\n",
    "    elif 700 <= num <= 799: return \"ì–¸ì–´\"\n",
    "    elif 800 <= num <= 899: return \"ë¬¸í•™\"\n",
    "    elif 900 <= num <= 999: return \"ì—­ì‚¬\"\n",
    "    else: return \"ê¸°íƒ€\"\n",
    "\n",
    "df[\"ë¶„ë¥˜\"] = df[\"ì²­êµ¬ê¸°í˜¸\"].apply(classify_subject)\n",
    "\n",
    "# ë¶„ì•¼ ë¦¬ìŠ¤íŠ¸\n",
    "subjects = [\"ì´ë¥˜\", \"ì² í•™\", \"ì¢…êµ\", \"ì‚¬íšŒê³¼í•™\", \"ìì—°ê³¼í•™\", \"ê¸°ìˆ ê³¼í•™\", \"ì˜ˆìˆ \", \"ì–¸ì–´\", \"ë¬¸í•™\", \"ì—­ì‚¬\", \"ê¸°íƒ€\"]\n",
    "\n",
    "# ì¶”ì²œ ì§‘ê³„ í•¨ìˆ˜\n",
    "def recommend_books(year, semester, category, top_n=3):\n",
    "    subset = df[(df[\"í•™ë…„\"] == year) & (df[\"í•™ê¸°\"] == semester) & (df[\"ë¶„ë¥˜\"] == category)]\n",
    "\n",
    "    if subset.empty:\n",
    "        return pd.DataFrame()  # ë¹ˆ DF ë°˜í™˜\n",
    "\n",
    "    book_counts = (\n",
    "        subset.groupby(\"ì„œëª…\")\n",
    "        .agg(\n",
    "            ëŒ€ì¶œíšŸìˆ˜=(\"ì„œëª…\", \"count\"),\n",
    "            ëŒ€ì¶œí•™ìƒìˆ˜=(\"í•™ë²ˆ\", \"nunique\")\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(by=\"ëŒ€ì¶œí•™ìƒìˆ˜\", ascending=False)\n",
    "    )\n",
    "    return book_counts.head(top_n)\n",
    "\n",
    "# ì „ì²´ ê²°ê³¼ ì €ì¥\n",
    "results = []\n",
    "\n",
    "for grade in range(1, 5):       # 1~4í•™ë…„\n",
    "    for semester in [1, 2]:     # 1í•™ê¸°, 2í•™ê¸°\n",
    "        for subject in subjects:\n",
    "            result = recommend_books(grade, semester, subject)\n",
    "            if not result.empty:\n",
    "                result[\"í•™ë…„\"] = grade\n",
    "                result[\"í•™ê¸°\"] = semester\n",
    "                result[\"ë¶„ì•¼\"] = subject\n",
    "                results.append(result)\n",
    "\n",
    "# ë¦¬ìŠ¤íŠ¸ â†’ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹˜ê¸°\n",
    "final_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# ë¶„ì•¼ â†’ í•™ë…„ â†’ í•™ê¸° ìˆœì„œë¡œ ì •ë ¬\n",
    "final_df = final_df.sort_values(\n",
    "    by=[\"ë¶„ì•¼\", \"í•™ë…„\", \"í•™ê¸°\"], \n",
    "    ascending=[True, True, True]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# CSVë¡œ ì €ì¥\n",
    "final_df.to_csv(\"../backend/data/recommend_all.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"âœ… ë¶„ì•¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ëœ recommend_all.csv íŒŒì¼ ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGAS í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±í•˜ê¸°\n",
    "### 1. CSV íŒŒì¼ -> RAG í‰ê°€ CSV í¬ë©§ìœ¼ë¡œ ë³€í™˜ \n",
    "- ìœ„ì—ì„œ ì‹œí–‰ëœ ë„ì„œ ì¶”ì²œ ëª©ë¡ csvíŒŒì¼ì„ RAG í‰ê°€ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë°˜í™˜\n",
    "- í‰ê°€ìš© ë°ì´í„°ì…‹ì„ í†µí•´ RAGAS í…ŒìŠ¤íŠ¸ ì§„í–‰\n",
    "\n",
    "### 2. ì›¹ë¬¸ì„œ ë°ì´í„° ê¸°ë°˜ í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±\n",
    "- í•œì„±ëŒ€í•™êµ í•™ìˆ ì •ë³´ê´€ ì´ìš© ì„¸ì¹™ì— ê´€í•œ ì›¹ ë¬¸ì„œ ë¡œë“œ\n",
    "- ì„¸ì¹™ì— ë§ê²Œ ì›¹ë¬¸ì„œì—ì„œ context ë§¤í•‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "# === 1. ì¶”ì²œ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸° ===\n",
    "df = pd.read_csv(\"../backend/data/recommend_all.csv\", encoding=\"utf-8\")\n",
    "\n",
    "rec_rows = []\n",
    "\n",
    "# === 2. ì¶”ì²œ ë„ì„œ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„± ===\n",
    "for (grade, semester, category), group in df.groupby([\"í•™ë…„\", \"í•™ê¸°\", \"ë¶„ì•¼\"]):\n",
    "    contexts = group[\"ì„œëª…\"].tolist()\n",
    "    # ground_truth = ëŒ€ì¶œí•™ìƒìˆ˜ ìƒìœ„ 3ê°œ\n",
    "    ground_truth_top3 = group.head(3)[\"ì„œëª…\"].tolist()\n",
    "\n",
    "    question = f\"{grade}í•™ë…„ {semester}í•™ê¸° {category} ë¶„ì•¼ì—ì„œ ì¶”ì²œí•  ë„ì„œëŠ”?\"\n",
    "\n",
    "    rec_rows.append({\n",
    "        \"question\": question,\n",
    "        \"contexts\": str(contexts),\n",
    "        \"ground_truth\": str(ground_truth_top3),  # ë¦¬ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ CSVì— ì €ì¥\n",
    "        \"source\": \"ë„ì„œëŒ€ì¶œë‚´ì—­.csv\"\n",
    "    })\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# === 2. ì›¹ ê·œì • ë°ì´í„° ê¸°ë°˜ í‰ê°€ì…‹ ìƒì„± ===\n",
    "url = \"https://hsel.hansung.ac.kr/intro_data.mir\"\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "rule_div = soup.find(\"div\", id=\"intro_rule\")\n",
    "\n",
    "contexts_rules = []\n",
    "for h4 in rule_div.find_all(\"h4\", class_=\"sub_title\"):\n",
    "    section_title = h4.get_text(strip=True)\n",
    "    ul = h4.find_next_sibling(\"ul\")\n",
    "    if ul:\n",
    "        items = [li.get_text(strip=True) for li in ul.find_all(\"li\")]\n",
    "        section_text = section_title + \" \" + \" \".join(items)\n",
    "        contexts_rules.append(section_text)\n",
    "\n",
    "rule_questions = [\n",
    "    \"ë„ì„œê´€ ì´ìš©ì‹œê°„ì€ ì–´ë–»ê²Œ ë¼?\",\n",
    "    \"ë„ì„œê´€ì˜ íœ´ê´€ì¼ì€ ì–´ë–»ê²Œ ë¼?\",\n",
    "    \"í•™ìˆ ì •ë³´ê´€ ì¬í•™ìƒ ëŒ€ì¶œê¸°ê°„ì€ ì–´ë–»ê²Œ ë¼?\",\n",
    "    \"í•™ìˆ ì •ë³´ê´€ êµì§ì› ëŒ€ì¶œê¸°ê°„ì€ ì–´ë–»ê²Œ ë¼?\"\n",
    "]\n",
    "rule_answers = [\n",
    "    \"1. ìë£Œì—´ëŒì‹¤ : í•™ê¸° ì¤‘ í‰ì¼ 09:00ï½21:00 í† ìš”ì¼ 11:00 ~ 15:00 í•™ê¸° ì¤‘ ë°©í•™ ì¤‘ í‰ì¼ 10:00ï½16:00 í† ìš”ì¼ íœ´ê´€2. ì¼ë°˜ì—´ëŒì‹¤ : ì—°ì¤‘ 06:30ï½23:00\",\n",
    "    \"1. ì¼ìš”ì¼, 2. ë²•ì •ê³µíœ´ì¼, 3. ê°œêµê¸°ë…ì¼\",\n",
    "    \"ì¬í•™ìƒ(í•™ë¶€) ëŒ€ì¶œê¸°ê°„ì€ 15ì¼, ëŒ€í•™ì›ì€ 30ì¼\",\n",
    "    \"êµì§ì› ëŒ€ì¶œê¸°ê°„ì€ ì§ì› 60ì¼, ì—°êµ¬ì› ë° ì¡°êµëŠ” 30ì¼\"\n",
    "]\n",
    "\n",
    "rule_rows = []\n",
    "for q, gt in zip(rule_questions, rule_answers):\n",
    "    rule_rows.append({\n",
    "        \"question\": q,\n",
    "        \"contexts\": str(contexts_rules),\n",
    "        \"ground_truth\": gt,\n",
    "        \"source\": \"í•™ìˆ ì •ë³´ê´€ê·œì •\"\n",
    "    })\n",
    "    \n",
    "# === 3. í†µí•© ë°ì´í„°ì…‹ ===\n",
    "eval_df = pd.DataFrame(rec_rows + rule_rows)\n",
    "\n",
    "# ì €ì¥\n",
    "eval_df.to_csv(\"../backend/data/ragas_eval_dataset.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"âœ… ragas_eval_dataset.csv ì €ì¥ ì™„ë£Œ!\")\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS í‰ê°€ ë‹¨ê³„\n",
    "- 1. í‰ê°€í•  ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "- 2. RAG ì²´ì¸ ì¤€ë¹„ (í‰ê°€í•  RAG íŒŒì´í”„ë¼ì¸ì„ ë¶ˆëŸ¬ì˜¤ê¸°)\n",
    "- 3. ë°°ì¹˜ ì‹¤í–‰ (ì˜ˆìƒ ë‹µë³€ ìƒì„±)\n",
    "- 4. RAGAS í‰ê°€ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import sys, os\n",
    "\n",
    "# backend/rag_core ê²½ë¡œ ì¶”ê°€í›„ ê¸°ì¡´ RAG íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ import\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from backend.rag_core.pipeline import ask, Book_RETRIEVER, Library_RETRIEVER, _extract_title, classify_simple, QueryType\n",
    "\n",
    "# 1. í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "df = pd.read_csv(\"../backend/data/ragas_eval_dataset.csv\")\n",
    "\n",
    "# 2. contextsê°€ ë¬¸ìì—´ í˜•íƒœì¼ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "def convert_contexts(question):\n",
    "    \"\"\"ì‹¤ì œ retriever ê²°ê³¼ë¥¼ contextsë¡œ ì‚¬ìš©\"\"\"\n",
    "    \n",
    "   # ì¿¼ë¦¬ íƒ€ì… ë¶„ë¥˜\n",
    "    query_type = classify_simple(question)\n",
    "    if query_type == QueryType.BOOK_RECOMMENDATION:\n",
    "        retriever = Book_RETRIEVER\n",
    "    else:\n",
    "        retriever = Library_RETRIEVER\n",
    "    \n",
    "    # ì‹¤ì œ retrieverë¡œ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    \n",
    "    # contexts: ì‹¤ì œ ê²€ìƒ‰ëœ ë¬¸ì„œì˜ content\n",
    "    actual_contexts = [doc.page_content for doc in retrieved_docs]\n",
    "    \n",
    "    # answer: ask() í•¨ìˆ˜ ê²°ê³¼\n",
    "    answer = ask(question)[\"answer\"]\n",
    "    \n",
    "    return {\n",
    "        'contexts': actual_contexts,\n",
    "        'answer': answer,\n",
    "        'retrieved_titles': [_extract_title(doc.page_content) for doc in retrieved_docs]  # ë””ë²„ê¹…ìš©\n",
    "    }\n",
    "\n",
    "# 3. ì‹¤ì œ ì‹œìŠ¤í…œìœ¼ë¡œ contextsì™€ answer ì¬ìƒì„±\n",
    "print(\"ğŸ”„ ì‹¤ì œ retriever ê²°ê³¼ë¡œ contexts ì¬ìƒì„± ì¤‘...\")\n",
    "\n",
    "results = []\n",
    "for idx, row in df.iterrows():\n",
    "    question = row['question']\n",
    "    print(f\"ì²˜ë¦¬ ì¤‘: {question}\")\n",
    "    \n",
    "    # ì‹¤ì œ ì‹œìŠ¤í…œ ì‹¤í–‰\n",
    "    result = convert_contexts(question)\n",
    "    \n",
    "    results.append({\n",
    "        'question': question,\n",
    "        'contexts': result['contexts'],  # ì‹¤ì œ retriever ê²°ê³¼\n",
    "        'answer': result['answer'],\n",
    "        'ground_truth': row['ground_truth'],\n",
    "        'source': row['source'],\n",
    "        'retrieved_titles': result['retrieved_titles']  # í™•ì¸ìš©\n",
    "    })\n",
    "    \n",
    "    print(f\"  ê²€ìƒ‰ëœ ì±…ë“¤: {result['retrieved_titles']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 4. ìƒˆë¡œìš´ DataFrame ìƒì„±\n",
    "corrected_df = pd.DataFrame(results)\n",
    "\n",
    "# 5. HuggingFace Datasetìœ¼ë¡œ ë³€í™˜\n",
    "eval_dataset = Dataset.from_pandas(corrected_df)\n",
    "\n",
    "print(\"âœ… ìˆ˜ì •ëœ evaluation dataset:\")\n",
    "print(eval_dataset)\n",
    "\n",
    "# 6. ìˆ˜ì •ëœ ë°ì´í„° ì €ì¥\n",
    "corrected_df.to_csv(\"../backend/data/ragas_eval_retriever_dat.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"âœ… ìˆ˜ì •ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=eval_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(result)          # dict í˜•íƒœ\n",
    "print(result.to_pandas())  # í‘œ í˜•íƒœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ragas í‰ê°€ ê²°ê³¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "result_df = result.to_pandas()\n",
    "\n",
    "# RAGASê²°ê³¼ CSVíŒŒì¼ë¡œ ì €ì¥\n",
    "result_df.to_csv(\"ragas_custom_retriever_result.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
